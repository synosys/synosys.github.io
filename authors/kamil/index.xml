<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kamil FuÅ‚awka | SynoSys</title>
    <link>https://synosys.github.io/authors/kamil/</link>
      <atom:link href="https://synosys.github.io/authors/kamil/index.xml" rel="self" type="application/rss+xml" />
    <description>Kamil FuÅ‚awka</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2025 Center Synergy of Systems</copyright><lastBuildDate>Sun, 03 Aug 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://synosys.github.io/authors/kamil/avatar_hueaffc988be1310b04c8e1596ab7cc80f_344026_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Kamil FuÅ‚awka</title>
      <link>https://synosys.github.io/authors/kamil/</link>
    </image>
    
    <item>
      <title>Preprint on decision-making and large language models</title>
      <link>https://synosys.github.io/news/preprint-data/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/preprint-data/</guid>
      <description>&lt;p&gt;Our colleague &lt;strong&gt;Kamil Fulawka&lt;/strong&gt; is the first author of a new preprint investigating how large language models (LLMs) can be used to understand the psychology of risky choice. Together with &lt;strong&gt;Ralph Hertwig&lt;/strong&gt; and &lt;strong&gt;Dirk Wulff&lt;/strong&gt;, he introduces a scalable approach to analyze participantsâ€™ free-text explanations of their decisions.&lt;/p&gt;
&lt;p&gt;The study shows that LLMs can accurately identify the reasons people give for their lottery choices in more than &lt;strong&gt;92% of cases&lt;/strong&gt;. These verbal reports reveal systematic patterns: peopleâ€™s reasoning depends strongly on the &lt;strong&gt;structure of the choice problem&lt;/strong&gt; rather than being fixed across individuals. Models based on these reason profiles also achieve &lt;strong&gt;higher predictive accuracy than prospect theory&lt;/strong&gt;, one of the most established frameworks in decision science.&lt;/p&gt;
&lt;p&gt;By demonstrating the &lt;strong&gt;scientific value of verbal data&lt;/strong&gt;, the work opens new avenues for developing context-aware models of human decision-making. We are proud of Kamilâ€™s contribution to this important line of research.&lt;/p&gt;
&lt;p&gt;ðŸ‘‰ &lt;a href=&#34;https://osf.io/preprints/psyarxiv/yuzmw_v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Read the preprint here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Statistical Modeling for Online Behavior Data</title>
      <link>https://synosys.github.io/teaching/stats_model/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/teaching/stats_model/</guid>
      <description>&lt;p&gt;Opal: &lt;a href=&#34;https://bildungsportal.sachsen.de/opal/auth/RepositoryEntry/48880648204/CourseNode/1743474776839555003&#34; target=&#34;_blank&#34;&gt;Link here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Time Thursdays, 5. DS&lt;/p&gt;
&lt;p&gt;Location BAR/0I89&lt;/p&gt;
&lt;p&gt;Department Computer Science&lt;/p&gt;
&lt;p&gt;Modules INF-BAS3 (Software- und Web-Engineering)&lt;/p&gt;
&lt;p&gt;Language English&lt;/p&gt;
&lt;p&gt;Assessment oral exam&lt;/p&gt;
&lt;h2 id=&#34;description&#34;&gt;Description:&lt;/h2&gt;
&lt;p&gt;Online platforms generate vast amounts of behavioral data, including subjective ratings (e.g., likes, stars, reactions) and objective engagement metrics (e.g., views, clicks, watch time). While machine learning excels at predicting user behavior, statistical modelingâ€”a cornerstone of empirical researchâ€”is critical for interpretable analysis. It helps uncover relationships between user behavior and various factors (e.g., how demographics influence engagement patterns) and enables causal inference in experiments (e.g., measuring the impact of different feed-ranking algorithms on user experience). These methods are widely used in UX research, product analytics, and A/B testing.&lt;/p&gt;
&lt;p&gt;This course provides a hands-on introduction to statistical modeling in R, focusing on methods most useful for analyzing behavioral data. We&amp;rsquo;ll cover key concepts and progress to model selection based on outcome type. Topics include logistic regression for binary outcomes (e.g., like/dislike reactions), ordinal regression for rating scales, beta regression for continuous feedback (e.g., sliders), and hierarchical models for nested data (e.g., multiple ratings from the same users). In the end, you&amp;rsquo;ll not only know which model to use but also how to effectively visualize and communicate your findings through clear, interpretable result presentations.&lt;/p&gt;
&lt;p&gt;No prior statistical modeling experience is required. If you&amp;rsquo;re familiar with Python or similar languages, the transition to R should be easy. All scripts and exercises are provided.&lt;/p&gt;
&lt;h3 id=&#34;schedule&#34;&gt;Schedule:&lt;/h3&gt;
&lt;p&gt;Part 1: General Introduction&lt;/p&gt;
&lt;p&gt;Week 1 Introduction to statistical modeling: goals and principles&lt;/p&gt;
&lt;p&gt;Week 2 Linear regression: the foundational model, applications and limitations&lt;/p&gt;
&lt;p&gt;Part 2: Selected Generalized Linear Models&lt;/p&gt;
&lt;p&gt;Week 1 Logistic regression 1: analysis of likes and dislikes&lt;/p&gt;
&lt;p&gt;Week 2 Logistic regression 2: multivariate analysis&lt;/p&gt;
&lt;p&gt;Week 3 Ordinal regression 1: stars and other likert-type ratings&lt;/p&gt;
&lt;p&gt;Week 4 Ordinal regression 2: modeling distributional parameters&lt;/p&gt;
&lt;p&gt;Week 5 Beta regression 1: slider-type ratings&lt;/p&gt;
&lt;p&gt;Week 6 Beta regression 2: modeling distributional parameters&lt;/p&gt;
&lt;p&gt;Week 7 Interim summary, additional exercises, and other GLMs&lt;/p&gt;
&lt;p&gt;Part 3: Experimental design &amp;amp; hierarchical models&lt;/p&gt;
&lt;p&gt;Week 1 Modeling between- and within-individual experimental designs&lt;/p&gt;
&lt;p&gt;Week 2 Hierarchical models 1: introduction&lt;/p&gt;
&lt;p&gt;Week 3 Hierarchical models 2: logistic and ordinal regression&lt;/p&gt;
&lt;p&gt;Week 4 Hierarchical models 3: Beta regression&lt;/p&gt;
&lt;p&gt;Week 5 Final session, Q&amp;amp;A, discussion and feedback&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
