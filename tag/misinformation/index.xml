<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Misinformation | SynoSys</title>
    <link>https://synosys.github.io/tag/misinformation/</link>
      <atom:link href="https://synosys.github.io/tag/misinformation/index.xml" rel="self" type="application/rss+xml" />
    <description>Misinformation</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 Center Synergy of Systems</copyright><lastBuildDate>Fri, 29 Nov 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://synosys.github.io/media/sharing.png</url>
      <title>Misinformation</title>
      <link>https://synosys.github.io/tag/misinformation/</link>
    </image>
    
    <item>
      <title>New multi-author preprint about who should govern online environments</title>
      <link>https://synosys.github.io/news/choice_architects/</link>
      <pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/choice_architects/</guid>
      <description>&lt;p&gt;In this multi-author paper, spearheaded by &lt;a href=&#34;https://www.mpib-berlin.mpg.de/person/friederike-stock/419405&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Friederike Stock&lt;/a&gt;, and as part of the &lt;a href=&#34;https://jrp.pscholars.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Junior Researcher Program&lt;/a&gt; with young researchers from 26 different countries and the project was supervised by Philipp Lorenz-Spreen. Little is known about who users themselves think should control their online environments, and under what circumstances. In our preregistered study, participants across 26 countries (N = 11,686) decided between combinations of three possible choice architects—governments, platforms, and individuals—and three objectives—societal, commercial, and personal—in seven real-world contexts. Across all countries, people strongly prefer to set their own rules for their online choice architectures. Find the full preprint &lt;a href=&#34;https://osf.io/preprints/osf/haqu9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Research Explores News Values in Perceived Misinformation Across 24 Countries</title>
      <link>https://synosys.github.io/news/fake_news_24/</link>
      <pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/fake_news_24/</guid>
      <description>&lt;p&gt;Sami Nenno, Postdoc in the Junior Research Group Computational Social Science at SynoSys, Center Synergy of Systems, has co-authored an insightful new paper, All the (Fake) News That’s Fit to Share? News Values in Perceived Misinformation Across Twenty-Four Countries. Co-written with Cornelius Puschmann, the study has been published in The International Journal of Press/Politics and investigates the relationship between journalistic news values and perceived misinformation in diverse national contexts.&lt;/p&gt;
&lt;p&gt;The research addresses a notable gap in the understanding of how misinformation is shaped and perceived globally. While much of the previous scholarship has focused on misinformation within WEIRD (Western, Educated, Industrialized, Rich, and Democratic) countries, this study expands the scope by including both WEIRD and non-WEIRD regions. Using a dataset of over 770,000 Facebook-shared URLs flagged as misinformation by users, the study analyzes the prevalence of five key news values: conflict, negativity, proximity, individualization, and informativeness. Through computational analysis, the authors explore how these news values appear in flagged and unflagged content and assess their variation across 24 countries.&lt;/p&gt;
&lt;p&gt;The research reveals that flagged content, often perceived as misinformation, tends to emphasize conflict and negativity more strongly than unflagged content. Other news values, such as proximity and individualization, also appear more prominently in flagged items, though with varying intensity. Significant differences in the prevalence of news values were observed between WEIRD and non-WEIRD countries. For instance, proximity and negativity were found to be more pronounced in WEIRD countries, whereas individualization was more prevalent in non-WEIRD contexts. The study also highlights unique patterns in countries such as the United States and Brazil, where conflict and negativity were particularly dominant in flagged content.&lt;/p&gt;
&lt;p&gt;The findings challenge existing frameworks of news values, which were primarily developed within Western contexts, by showing that these models may not fully account for the diversity of global media landscapes. This emphasizes the need for more inclusive theoretical models that better reflect regional and cultural differences.&lt;/p&gt;
&lt;p&gt;This study contributes to the growing field of misinformation research by providing a global perspective on how news values intersect with perceived misinformation. It highlights the influence of journalistic styles and national media systems on the characteristics of flagged content, offering valuable insights for academics, journalists, and policymakers seeking to address the challenges posed by misinformation.&lt;/p&gt;
&lt;p&gt;This publication was part of Sami Nenno&amp;rsquo;s PhD project and was written during his time at the University of Bremen and at the Alexander von Humboldt Institute for Internet and Society. He recently joined Synosys to continue his work. The paper is accessible online at &lt;a href=&#34;https://journals.sagepub.com/doi/10.1177/19401612241311893&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Study Reveals Who’s Most Vulnerable to Misinformation—and why</title>
      <link>https://synosys.github.io/news/misinformation/</link>
      <pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/misinformation/</guid>
      <description>&lt;p&gt;Our junior research group leader Philipp Lorenz-Spreen, whose work focuses on the digital information environment and among other things on misinformation, has co-authored a comprehensive meta-analysis of over 256,000 decisions from thousands of participants that sheds light on who is most susceptible to misinformation and the factors behind it. Their research reveals that susceptibility depends less on formal education and more on individual and contextual factors, such as age, analytical thinking, and political alignment. Older adults and those with strong analytical skills tend to discern truth from falsehood better, though they are also more skeptical, which means they classify more news as false overall. A tendency called “true news bias” emerges when people encounter news aligning with their political beliefs or previously seen content, making them more prone to believe information without scrutiny. These findings offer valuable insights for his further studies of the spreading dynamics of misinformation and the development of interventions that help people to navigate the information environment of the internet. &lt;a href=&#34;https://doi.org/10.1073/pnas.2409329121&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Read in full here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
