<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Misinformation | SynoSys</title>
    <link>https://synosys.github.io/tag/misinformation/</link>
      <atom:link href="https://synosys.github.io/tag/misinformation/index.xml" rel="self" type="application/rss+xml" />
    <description>Misinformation</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>¬© 2026 Center Synergy of Systems</copyright><lastBuildDate>Tue, 23 Sep 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://synosys.github.io/media/sharing.png</url>
      <title>Misinformation</title>
      <link>https://synosys.github.io/tag/misinformation/</link>
    </image>
    
    <item>
      <title>Is public broadcasting an amplifier or a gatekeeper of misinformation?</title>
      <link>https://synosys.github.io/news/public_broadcasting_misinformation/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/public_broadcasting_misinformation/</guid>
      <description>&lt;p&gt;Sami Nenno, Postdoc in the Junior Research Group Computational Social Science at SynoSys, Center Synergy of Systems, has published a new article in &lt;em&gt;Information, Communication &amp;amp; Society&lt;/em&gt; that addresses the question: &lt;strong&gt;Is public broadcasting an amplifier or a gatekeeper of misinformation?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the study, he collected fact-checking articles and matched them with subtitles from more than 1,000 news and talk show episodes on German public broadcasting television. The findings show that at least one claim qualifying as misinformation appears in over 12% of talk show episodes and about 2% of news programs.&lt;/p&gt;
&lt;p&gt;Such claims are most often made by politicians. While they are sometimes challenged by moderators or other guests, in many cases they remain unaddressed. The misinformation ranges from narratives about migration ‚Äúpull factors‚Äù to climate policy. However, the study finds no evidence that viral online misinformation is being transmitted on television.&lt;/p&gt;
&lt;p&gt;This suggests that although gatekeeping frequently fails, public broadcasting does not serve as an amplifier either. Instead, two distinct forms emerge: online misinformation, which is often outlandish and unrelated to current public discourse, and misinformation tied to high-profile political events that circulates both online and in traditional media.&lt;/p&gt;
&lt;p&gt;The research underscores the need to broaden the scope of misinformation research and highlights the difficulty journalists face in countering false claims, particularly in live, contentious debates.&lt;/p&gt;
&lt;p&gt;üëâ &lt;a href=&#34;https://www.tandfonline.com/doi/full/10.1080/1369118X.2025.2561030&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Read the full article here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Separate worlds of misinformation. An explorative study of checked claims in German public broadcast news and talk shows.</title>
      <link>https://synosys.github.io/publication/sami_talk_shows_2025/</link>
      <pubDate>Tue, 29 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/publication/sami_talk_shows_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New multi-author preprint about who should govern online environments</title>
      <link>https://synosys.github.io/news/choice_architects/</link>
      <pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/choice_architects/</guid>
      <description>&lt;p&gt;In this multi-author paper, spearheaded by &lt;a href=&#34;https://www.mpib-berlin.mpg.de/person/friederike-stock/419405&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Friederike Stock&lt;/a&gt;, and as part of the &lt;a href=&#34;https://jrp.pscholars.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Junior Researcher Program&lt;/a&gt; with young researchers from 26 different countries and the project was supervised by Philipp Lorenz-Spreen. Little is known about who users themselves think should control their online environments, and under what circumstances. In our preregistered study, participants across 26 countries (N = 11,686) decided between combinations of three possible choice architects‚Äîgovernments, platforms, and individuals‚Äîand three objectives‚Äîsocietal, commercial, and personal‚Äîin seven real-world contexts. Across all countries, people strongly prefer to set their own rules for their online choice architectures. Find the full preprint &lt;a href=&#34;https://osf.io/preprints/osf/haqu9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Research Explores News Values in Perceived Misinformation Across 24 Countries</title>
      <link>https://synosys.github.io/news/fake_news_24/</link>
      <pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/fake_news_24/</guid>
      <description>&lt;p&gt;Sami Nenno, Postdoc in the Junior Research Group Computational Social Science at SynoSys, Center Synergy of Systems, has co-authored an insightful new paper, All the (Fake) News That‚Äôs Fit to Share? News Values in Perceived Misinformation Across Twenty-Four Countries. Co-written with Cornelius Puschmann, the study has been published in The International Journal of Press/Politics and investigates the relationship between journalistic news values and perceived misinformation in diverse national contexts.&lt;/p&gt;
&lt;p&gt;The research addresses a notable gap in the understanding of how misinformation is shaped and perceived globally. While much of the previous scholarship has focused on misinformation within WEIRD (Western, Educated, Industrialized, Rich, and Democratic) countries, this study expands the scope by including both WEIRD and non-WEIRD regions. Using a dataset of over 770,000 Facebook-shared URLs flagged as misinformation by users, the study analyzes the prevalence of five key news values: conflict, negativity, proximity, individualization, and informativeness. Through computational analysis, the authors explore how these news values appear in flagged and unflagged content and assess their variation across 24 countries.&lt;/p&gt;
&lt;p&gt;The research reveals that flagged content, often perceived as misinformation, tends to emphasize conflict and negativity more strongly than unflagged content. Other news values, such as proximity and individualization, also appear more prominently in flagged items, though with varying intensity. Significant differences in the prevalence of news values were observed between WEIRD and non-WEIRD countries. For instance, proximity and negativity were found to be more pronounced in WEIRD countries, whereas individualization was more prevalent in non-WEIRD contexts. The study also highlights unique patterns in countries such as the United States and Brazil, where conflict and negativity were particularly dominant in flagged content.&lt;/p&gt;
&lt;p&gt;The findings challenge existing frameworks of news values, which were primarily developed within Western contexts, by showing that these models may not fully account for the diversity of global media landscapes. This emphasizes the need for more inclusive theoretical models that better reflect regional and cultural differences.&lt;/p&gt;
&lt;p&gt;This study contributes to the growing field of misinformation research by providing a global perspective on how news values intersect with perceived misinformation. It highlights the influence of journalistic styles and national media systems on the characteristics of flagged content, offering valuable insights for academics, journalists, and policymakers seeking to address the challenges posed by misinformation.&lt;/p&gt;
&lt;p&gt;This publication was part of Sami Nenno&amp;rsquo;s PhD project and was written during his time at the University of Bremen and at the Alexander von Humboldt Institute for Internet and Society. He recently joined Synosys to continue his work. The paper is accessible online at &lt;a href=&#34;https://journals.sagepub.com/doi/10.1177/19401612241311893&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Study Reveals Who‚Äôs Most Vulnerable to Misinformation‚Äîand why</title>
      <link>https://synosys.github.io/news/misinformation/</link>
      <pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://synosys.github.io/news/misinformation/</guid>
      <description>&lt;p&gt;Our junior research group leader Philipp Lorenz-Spreen, whose work focuses on the digital information environment and among other things on misinformation, has co-authored a comprehensive meta-analysis of over 256,000 decisions from thousands of participants that sheds light on who is most susceptible to misinformation and the factors behind it. Their research reveals that susceptibility depends less on formal education and more on individual and contextual factors, such as age, analytical thinking, and political alignment. Older adults and those with strong analytical skills tend to discern truth from falsehood better, though they are also more skeptical, which means they classify more news as false overall. A tendency called ‚Äútrue news bias‚Äù emerges when people encounter news aligning with their political beliefs or previously seen content, making them more prone to believe information without scrutiny. These findings offer valuable insights for his further studies of the spreading dynamics of misinformation and the development of interventions that help people to navigate the information environment of the internet. &lt;a href=&#34;https://doi.org/10.1073/pnas.2409329121&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Read in full here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
